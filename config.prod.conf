[openrouter]
api_key = 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
base_url = https://openrouter.ai/api/v1
timeout = 60
# Rate limiting to prevent API key bans in production
min_delay = 1.0
max_delay = 2.0
max_concurrent = 1
# Special delay for free models (even more restrictive in production)
free_model_delay = 8.0
# Circuit breaker for free models to prevent cascading failures (more conservative in prod)
free_model_max_errors = 2
free_model_cooldown = 60

[models]
# Premium models for production
gpt4 = openai/gpt-4
claude = anthropic/claude-3-5-sonnet-20241022
gemini = google/gemini-2.5-flash-preview-05-20
llama = meta-llama/llama-3.3-70b-instruct

# Free models from the database
mistral = mistralai/devstral-small:free
zephyr = deepseek/deepseek-r1-0528-qwen3-8b:free
openchat = sarvamai/sarvam-m:free
vicuna = google/gemma-3n-e4b-it:free
alpaca = meta-llama/llama-3.2-3b-instruct:free
wizard = nousresearch/deephermes-3-mistral-24b-preview:free

[server]
host = 0.0.0.0
port = 8000
reload = false

[logging]
debug = false
level = INFO
console_output = true
file_output = true
log_file = ./logs/backend.log

[frontend]
# Production frontend URL
url = https://roundtaible.vercel.app
# Timeout for API calls to frontend (seconds)
timeout = 15

[database]
# Note: Python backend uses HTTP API calls to Next.js frontend for database access
# Frontend Next.js handles PostgreSQL connection directly  
database_url = postgresql://postgres.rapggquwtgbngmlhbxtp:MariachiaraStefania01@aws-0-eu-central-1.pooler.supabase.com:6543/postgres

[cors]
allowed_origins = https://roundtaible.vercel.app,http://localhost:3000