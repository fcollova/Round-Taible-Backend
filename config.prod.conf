[openrouter]
api_key = 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
base_url = https://openrouter.ai/api/v1
timeout = 60
# Rate limiting to prevent API key bans in production
min_delay = 1.0
max_delay = 2.0
max_concurrent = 1
# Special delay for free models (even more restrictive in production)
free_model_delay = 8.0
# Circuit breaker for free models to prevent cascading failures (more conservative in prod)
free_model_max_errors = 2
free_model_cooldown = 60

# Models are now retrieved from frontend API /api/models

[server]
host = 0.0.0.0
port = 8000
reload = false

[logging]
debug = false
level = INFO
console_output = true
file_output = true
log_file = ./logs/backend.log

# Livelli specifici per modulo in produzione (pi√π conservativi)
[logging.modules]
llm_queue_manager = INFO
debate_manager = INFO
websocket_manager = WARNING
openrouter_client = WARNING
main = INFO

[frontend]
# Production frontend URL
url = https://roundtaible.vercel.app
# Timeout for API calls to frontend (seconds)
timeout = 15

[database]
# Note: Python backend uses HTTP API calls to Next.js frontend for database access
# Frontend Next.js handles PostgreSQL connection directly  
database_url = postgresql://postgres.rapggquwtgbngmlhbxtp:MariachiaraStefania01@aws-0-eu-central-1.pooler.supabase.com:6543/postgres

[cors]
allowed_origins = https://roundtaible.vercel.app,http://localhost:3000